{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SimpleSequentialChain chain...\u001b[0m\n",
      "\u001b[36;1m\u001b[1;3mDynamic and fast\n",
      "JavaScript weaves magic code\n",
      "Web's heart beats with it\u001b[0m\n",
      "\u001b[33;1m\u001b[1;3mThis Haiku is describing JavaScript, a popular programming language used for building dynamic and interactive websites. The first line, \"Dynamic and fast,\" highlights the dynamic nature of JavaScript, which allows for real-time changes and updates on web pages. The second line, \"JavaScript weaves magic code,\" suggests that JavaScript has the ability to create powerful and engaging features on websites. Finally, the third line, \"Web's heart beats with it,\" emphasizes the importance of JavaScript in the functioning and overall user experience of the web. Overall, this Haiku captures the essence of JavaScript as a versatile and essential tool for web development.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'This Haiku is describing JavaScript, a popular programming language used for building dynamic and interactive websites. The first line, \"Dynamic and fast,\" highlights the dynamic nature of JavaScript, which allows for real-time changes and updates on web pages. The second line, \"JavaScript weaves magic code,\" suggests that JavaScript has the ability to create powerful and engaging features on websites. Finally, the third line, \"Web\\'s heart beats with it,\" emphasizes the importance of JavaScript in the functioning and overall user experience of the web. Overall, this Haiku captures the essence of JavaScript as a versatile and essential tool for web development.'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate,PromptTemplate\n",
    "from langchain.chains import LLMChain, SimpleSequentialChain\n",
    "\n",
    "\n",
    "llm = OpenAI(model_name=\"gpt-3.5-turbo-instruct\")\n",
    "chat = ChatOpenAI(model_name=\"gpt-3.5-turbo\")\n",
    "\n",
    "# First Chain: Generates a Haiku about a given programming language\n",
    "haiku_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Write a Haiku about the programming language {language}. It should capture its essence and characteristics.\"\n",
    ")\n",
    "haiku_chain = LLMChain(llm=ChatOpenAI(model=\"gpt-3.5-turbo\"), prompt=haiku_prompt)\n",
    "\n",
    "# Second Chain: Explains the Haiku\n",
    "explanation_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Explain the meaning of the following Haiku about a programming language:\\n\\n{haiku}\\n\\nProvide an insightful explanation.\"\n",
    ")\n",
    "explanation_chain = LLMChain(llm=ChatOpenAI(model=\"gpt-3.5-turbo\"), prompt=explanation_prompt)\n",
    "\n",
    "# Chain them together\n",
    "final_chain = SimpleSequentialChain(chains=[haiku_chain, explanation_chain], verbose=True)\n",
    "\n",
    "final_chain.run(\"javascript\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**제목:** 가나의 혼인잔치\n",
      "**감독:** 조지 클루니\n",
      "**주연:** 조지 클루니, 애미 아담스, 존 트라볼타, 크리스토퍼 워컨\n",
      "**예산:** 알려지지 않음\n",
      "**박스오피스 수익:** 3,100만 달러\n",
      "**장르:** 코미디, 드라마\n",
      "**시놉시스:** 1950년대 미국, 빈곤한 가나와 그의 아내 로즈는 부자 가족의 혼인식에 초대받게 된다. 그러나 가난한 가나와 로즈가 혼인식에 참석하게 되면서 예상치 못한 사건이 벌어지게 된다.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.prompts.few_shot import FewShotPromptTemplate\n",
    "\n",
    "# ✅ 예제 데이터 (Few-Shot Learning)\n",
    "examples = [\n",
    "    {\n",
    "        \"movie\": \"인셉션\",\n",
    "        \"response\": (\n",
    "            \"**제목:** 인셉션\\n\"\n",
    "            \"**감독:** 크리스토퍼 놀란\\n\"\n",
    "            \"**주연:** 레오나르도 디카프리오, 조셉 고든 레빗, 엘리엇 페이지, 톰 하디\\n\"\n",
    "            \"**예산:** 1억 6천만 달러\\n\"\n",
    "            \"**박스오피스 수익:** 8억 2,990만 달러\\n\"\n",
    "            \"**장르:** SF, 스릴러\\n\"\n",
    "            \"**시놉시스:** 꿈속에서 정보를 훔치는 특수 요원 '돔 코브'는 기억을 지울 수 있는 새로운 임무를 맡게 된다. 그러나 꿈의 세계에서 현실과 환상이 뒤섞이며 예상치 못한 위기가 닥친다.\"\n",
    "        ),\n",
    "    },\n",
    "    {\n",
    "        \"movie\": \"대부\",\n",
    "        \"response\": (\n",
    "            \"**제목:** 대부\\n\"\n",
    "            \"**감독:** 프란시스 포드 코폴라\\n\"\n",
    "            \"**주연:** 말론 브란도, 알 파치노, 제임스 칸, 다이안 키튼\\n\"\n",
    "            \"**예산:** 600~720만 달러\\n\"\n",
    "            \"**박스오피스 수익:** 2억 5천만~2억 8천 7백만 달러\\n\"\n",
    "            \"**장르:** 범죄, 드라마\\n\"\n",
    "            \"**시놉시스:** 뉴욕 마피아의 대부 비토 코를레오네는 조직을 이끌어가지만, 암살 시도 이후 아들 마이클 코를레오네가 가업을 물려받으며 변화가 찾아온다.\"\n",
    "        ),\n",
    "    }\n",
    "]\n",
    "\n",
    "# ✅ 예제 출력 형식을 위한 프롬프트 템플릿\n",
    "example_prompt = PromptTemplate.from_template(\n",
    "    \"영화 제목: {movie}\\n응답:\\n{response}\"\n",
    ")\n",
    "\n",
    "# ✅ FewShotPromptTemplate 생성\n",
    "few_shot_prompt = FewShotPromptTemplate(\n",
    "    examples=examples,\n",
    "    example_prompt=example_prompt,\n",
    "    prefix=\"당신은 영화 데이터베이스 전문가입니다. 주어진 영화 제목에 대해 항상 동일한 형식으로 정보를 제공합니다.\",\n",
    "    suffix=\"영화 제목: {movie}\\n응답:\",\n",
    "    input_variables=[\"movie\"]\n",
    ")\n",
    "\n",
    "# ✅ LLM 체인 생성\n",
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\")\n",
    "movie_chain = LLMChain(llm=llm, prompt=few_shot_prompt)\n",
    "\n",
    "# ✅ 영화 정보를 가져오는 함수\n",
    "def get_movie_details(movie_name):\n",
    "    return movie_chain.run({\"movie\": movie_name})\n",
    "\n",
    "# ✅ 실행 예제\n",
    "movie_name = \"가나의 혼인잔치\"  # 원하는 영화 제목으로 변경 가능\n",
    "result = get_movie_details(movie_name)\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "# ✅ Few-Shot 예제 데이터 (항상 3개의 이모지를 반환하도록 유도)\n",
    "examples = [\n",
    "    {\"movie\": \"Top Gun\", \"emojis\": \"🛩️👨‍✈️🔥\"},\n",
    "    {\"movie\": \"The Godfather\", \"emojis\": \"👨‍👨‍👦🔫🍝\"},\n",
    "    {\"movie\": \"Finding Nemo\", \"emojis\": \"🐠🌊🦈\"},\n",
    "    {\"movie\": \"Titanic\", \"emojis\": \"🚢❤️💔\"},\n",
    "    {\"movie\": \"Harry Potter\", \"emojis\": \"⚡📖🧙\"},\n",
    "]\n",
    "\n",
    "# ✅ FewShotPromptTemplate 설정\n",
    "example_prompt = PromptTemplate(\n",
    "    input_variables=[\"movie\", \"emojis\"],\n",
    "    template=\"Movie: {movie}\\n Emojis: {emojis}\"\n",
    ")\n",
    "\n",
    "few_shot_prompt = FewShotPromptTemplate(\n",
    "    examples=examples,\n",
    "    example_prompt=example_prompt,\n",
    "    prefix=\"You are a movie expert. Based on the movie title, provide exactly 3 emojis that best represent it.\\n\\nPrevious History:\\n{chat_history}\\n\\n\",\n",
    "    suffix=\"Movie: {movie}\\nEmojis:\",\n",
    "    input_variables=[\"movie\"]\n",
    ")\n",
    "\n",
    "# ✅ Memory 설정 (메모리 유지)\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\",max_token_limit=100 , return_messages=True,k=5)\n",
    "\n",
    "# ✅ LLM 체인 생성\n",
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\")\n",
    "emoji_chain = LLMChain(llm=llm, prompt=few_shot_prompt, memory=memory)\n",
    "\n",
    "# ✅ 체인 실행 함수\n",
    "def get_movie_emojis(movie_name):\n",
    "    return emoji_chain.run({\"movie\": movie_name})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First movie (Avatar): 🌎💙👽\n",
      "Second movie (The Matrix): 🕶️💻🔵\n",
      "Third movie (Jurassic Park): 🦕🌴🔬\n",
      "Fourth movie (Star Wars): 🌌⚔️🤖\n"
     ]
    }
   ],
   "source": [
    "# ✅ 첫 번째 영화 질문\n",
    "first_movie = \"Avatar\"\n",
    "first_result = get_movie_emojis(first_movie)\n",
    "print(f\"First movie ({first_movie}): {first_result}\")\n",
    "\n",
    "# ✅ 두 번째 영화 질문\n",
    "second_movie = \"The Matrix\"\n",
    "second_result = get_movie_emojis(second_movie)\n",
    "print(f\"Second movie ({second_movie}): {second_result}\")\n",
    "\n",
    "# ✅ 세 번째 영화 질문\n",
    "third_movie = \"Jurassic Park\"\n",
    "third_result = get_movie_emojis(third_movie)\n",
    "print(f\"Third movie ({third_movie}): {third_result}\")\n",
    "\n",
    "# ✅ 네 번째 영화 질문 (이제 첫 번째 영화는 메모리에서 사라짐)\n",
    "fourth_movie = \"Star Wars\"\n",
    "fourth_result = get_movie_emojis(fourth_movie)\n",
    "print(f\"Fourth movie ({fourth_movie}): {fourth_result}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result 🌎💙👽\n",
      "Memory Recall: {'chat_history': [HumanMessage(content='Avatar'), AIMessage(content='🌎💙👽'), HumanMessage(content='The Matrix'), AIMessage(content='🕶️💻🔵'), HumanMessage(content='Jurassic Park'), AIMessage(content='🦕🌴🔬'), HumanMessage(content='Star Wars'), AIMessage(content='🌌⚔️🤖'), HumanMessage(content='Avatar'), AIMessage(content='🌎💙👽')]}\n"
     ]
    }
   ],
   "source": [
    "# ✅ 이전에 질문한 영화 기억하는지 확인\n",
    "previous_result = get_movie_emojis(\"Avatar\")\n",
    "print(\"result\", previous_result)\n",
    "previous_question = emoji_chain.memory.load_memory_variables({})\n",
    "print(\"Memory Recall:\", previous_question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 1444, which is longer than the specified 1000\n",
      "Created a chunk of size 1251, which is longer than the specified 1000\n",
      "Created a chunk of size 1012, which is longer than the specified 1000\n",
      "Created a chunk of size 2313, which is longer than the specified 1000\n",
      "Created a chunk of size 1458, which is longer than the specified 1000\n",
      "Created a chunk of size 1673, which is longer than the specified 1000\n",
      "Created a chunk of size 1137, which is longer than the specified 1000\n",
      "Created a chunk of size 1559, which is longer than the specified 1000\n",
      "Created a chunk of size 1200, which is longer than the specified 1000\n",
      "Created a chunk of size 1042, which is longer than the specified 1000\n",
      "Created a chunk of size 1345, which is longer than the specified 1000\n",
      "Created a chunk of size 1339, which is longer than the specified 1000\n",
      "Created a chunk of size 1288, which is longer than the specified 1000\n",
      "Created a chunk of size 1014, which is longer than the specified 1000\n",
      "Created a chunk of size 1178, which is longer than the specified 1000\n",
      "Created a chunk of size 2247, which is longer than the specified 1000\n",
      "Created a chunk of size 1728, which is longer than the specified 1000\n"
     ]
    },
    {
     "ename": "ValidationError",
     "evalue": "1 validation error for StuffDocumentsChain\n__root__\n  document_variable_name context was not found in llm_chain input_variables: ['question', 'summaries'] (type=value_error)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 39\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m# ✅ 7. StuffDocuments Chain 수동 구성\u001b[39;00m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchains\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mretrieval_qa\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RetrievalQA\n\u001b[0;32m---> 39\u001b[0m rag_chain \u001b[38;5;241m=\u001b[39m \u001b[43mRetrievalQA\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_chain_type\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[43m    \u001b[49m\u001b[43mllm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mChatOpenAI\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgpt-3.5-turbo\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretriever\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretriever\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchain_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstuff\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchain_type_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprompt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mPROMPT\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmemory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_source_documents\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[1;32m     46\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/project/fullstack-gpt/env/lib/python3.10/site-packages/langchain/chains/retrieval_qa/base.py:100\u001b[0m, in \u001b[0;36mBaseRetrievalQA.from_chain_type\u001b[0;34m(cls, llm, chain_type, chain_type_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Load chain from chain type.\"\"\"\u001b[39;00m\n\u001b[1;32m     99\u001b[0m _chain_type_kwargs \u001b[38;5;241m=\u001b[39m chain_type_kwargs \u001b[38;5;129;01mor\u001b[39;00m {}\n\u001b[0;32m--> 100\u001b[0m combine_documents_chain \u001b[38;5;241m=\u001b[39m \u001b[43mload_qa_chain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    101\u001b[0m \u001b[43m    \u001b[49m\u001b[43mllm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchain_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchain_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m_chain_type_kwargs\u001b[49m\n\u001b[1;32m    102\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(combine_documents_chain\u001b[38;5;241m=\u001b[39mcombine_documents_chain, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/project/fullstack-gpt/env/lib/python3.10/site-packages/langchain/chains/question_answering/__init__.py:249\u001b[0m, in \u001b[0;36mload_qa_chain\u001b[0;34m(llm, chain_type, verbose, callback_manager, **kwargs)\u001b[0m\n\u001b[1;32m    244\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chain_type \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m loader_mapping:\n\u001b[1;32m    245\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    246\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGot unsupported chain type: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mchain_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    247\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloader_mapping\u001b[38;5;241m.\u001b[39mkeys()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    248\u001b[0m     )\n\u001b[0;32m--> 249\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mloader_mapping\u001b[49m\u001b[43m[\u001b[49m\u001b[43mchain_type\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    250\u001b[0m \u001b[43m    \u001b[49m\u001b[43mllm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    251\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/project/fullstack-gpt/env/lib/python3.10/site-packages/langchain/chains/question_answering/__init__.py:81\u001b[0m, in \u001b[0;36m_load_stuff_chain\u001b[0;34m(llm, prompt, document_variable_name, verbose, callback_manager, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m     73\u001b[0m llm_chain \u001b[38;5;241m=\u001b[39m LLMChain(\n\u001b[1;32m     74\u001b[0m     llm\u001b[38;5;241m=\u001b[39mllm,\n\u001b[1;32m     75\u001b[0m     prompt\u001b[38;5;241m=\u001b[39m_prompt,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     78\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39mcallbacks,\n\u001b[1;32m     79\u001b[0m )\n\u001b[1;32m     80\u001b[0m \u001b[38;5;66;03m# TODO: document prompt\u001b[39;00m\n\u001b[0;32m---> 81\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mStuffDocumentsChain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     82\u001b[0m \u001b[43m    \u001b[49m\u001b[43mllm_chain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mllm_chain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     83\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdocument_variable_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdocument_variable_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     84\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     85\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallback_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     86\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     87\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     88\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/project/fullstack-gpt/env/lib/python3.10/site-packages/langchain/load/serializable.py:97\u001b[0m, in \u001b[0;36mSerializable.__init__\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 97\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lc_kwargs \u001b[38;5;241m=\u001b[39m kwargs\n",
      "File \u001b[0;32m~/project/fullstack-gpt/env/lib/python3.10/site-packages/pydantic/v1/main.py:341\u001b[0m, in \u001b[0;36mBaseModel.__init__\u001b[0;34m(__pydantic_self__, **data)\u001b[0m\n\u001b[1;32m    339\u001b[0m values, fields_set, validation_error \u001b[38;5;241m=\u001b[39m validate_model(__pydantic_self__\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m, data)\n\u001b[1;32m    340\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m validation_error:\n\u001b[0;32m--> 341\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m validation_error\n\u001b[1;32m    342\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    343\u001b[0m     object_setattr(__pydantic_self__, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__dict__\u001b[39m\u001b[38;5;124m'\u001b[39m, values)\n",
      "\u001b[0;31mValidationError\u001b[0m: 1 validation error for StuffDocumentsChain\n__root__\n  document_variable_name context was not found in llm_chain input_variables: ['question', 'summaries'] (type=value_error)"
     ]
    }
   ],
   "source": [
    "from langchain.document_loaders import UnstructuredFileLoader\n",
    "import requests\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.chains.qa_with_sources.stuff_prompt import PROMPT\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "# ✅ 1. 문서 가져오기 (from Gist)\n",
    "url = \"https://gist.githubusercontent.com/serranoarevalo/5acf755c2b8d83f1707ef266b82ea223/raw\"\n",
    "response = requests.get(url)\n",
    "text = response.text\n",
    "\n",
    "# ✅ 2. 문서를 LangChain 문서 형태로 변환\n",
    "docs = [Document(page_content=text)]\n",
    "\n",
    "# ✅ 3. 문서 분할 (StuffDocuments는 전체 텍스트를 그대로 사용 가능하지만 RAG 효율을 위해 나눕니다)\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
    "split_docs = text_splitter.split_documents(docs)\n",
    "\n",
    "# ✅ 4. 벡터 저장소 구축 (Embedding + Vectorstore)\n",
    "embedding = OpenAIEmbeddings()\n",
    "vectorstore = FAISS.from_documents(split_docs, embedding)\n",
    "\n",
    "# ✅ 5. Retriever 설정\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "# ✅ 6. Memory 설정\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
    "\n",
    "# ✅ 7. StuffDocuments Chain 수동 구성\n",
    "from langchain.chains.retrieval_qa.base import RetrievalQA\n",
    "\n",
    "rag_chain = RetrievalQA.from_chain_type(\n",
    "    llm=ChatOpenAI(model_name=\"gpt-3.5-turbo\"),\n",
    "    retriever=retriever,\n",
    "    chain_type=\"stuff\",\n",
    "    chain_type_kwargs={\"prompt\": PROMPT},\n",
    "    memory=memory,\n",
    "    return_source_documents=True\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
